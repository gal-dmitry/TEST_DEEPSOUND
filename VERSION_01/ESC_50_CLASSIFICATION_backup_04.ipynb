{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40608,
     "status": "ok",
     "timestamp": 1662379296648,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "8LoG6iQydQtQ",
    "outputId": "844c1460-8e05-41f1-90a7-2be0ff8cdbaf"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1662379298864,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "sBFI3cZPdYgO",
    "outputId": "0691df78-e653-47eb-a216-9d11b805304d"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1662379304890,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "QIhwkaeRcVRh"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1662379308773,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "cyp3HvfAcVRn"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2412,
     "status": "ok",
     "timestamp": 1662379308772,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "cMMqHCxncVRm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision.models import resnet34\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import librosa\n",
    "from librosa.display import specshow\n",
    "from librosa.display import waveshow\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.feature import mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bb_o3LspcVRo"
   },
   "source": [
    "###### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uU2s-BOtcVRq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU0TwVk8cVRs"
   },
   "source": [
    "###### Case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1662379315483,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "G_flueZxcVRt"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Wave & features\n",
    "\"\"\"\n",
    "def transform_image(resize_shape=(32, 32)):\n",
    "    data_transform = transforms.Compose([\n",
    "            transforms.Resize(resize_shape),\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "    return data_transform\n",
    "    \n",
    "\n",
    "def spec_to_image(spec, eps=1e-6):\n",
    "    mean = spec.mean()\n",
    "    std = spec.std()\n",
    "    spec_norm = (spec - mean) / (std + eps)\n",
    "    spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "    spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "    spec_scaled = spec_scaled.astype(np.uint8)\n",
    "    return spec_scaled\n",
    "\n",
    "\n",
    "def get_wave(path, sr=None):\n",
    "    wav, sr = librosa.load(path, sr=sr)\n",
    "    return wav, sr\n",
    "\n",
    "\n",
    "def get_feature(wav,\n",
    "                data_transform=None,\n",
    "                power_to_db=True,\n",
    "                to_img=True,\n",
    "                feature=melspectrogram,\n",
    "                sr=None,\n",
    "                n_fft=2048, \n",
    "                hop_length=512, \n",
    "                n_mels=128, \n",
    "                fmin=20, \n",
    "                fmax=8300, \n",
    "                top_db=80):\n",
    "    \n",
    "    spec = feature(wav, \n",
    "                  sr=sr,\n",
    "                  n_fft=n_fft,\n",
    "                  hop_length=hop_length,\n",
    "                  n_mels=n_mels,\n",
    "                  fmin=fmin,\n",
    "                  fmax=fmax)\n",
    "\n",
    "    if power_to_db:\n",
    "        spec = librosa.power_to_db(spec, top_db=top_db)\n",
    "    \n",
    "    if to_img:\n",
    "        spec = spec_to_image(spec)\n",
    "    \n",
    "    if data_transform is not None:\n",
    "        spec = Image.fromarray(spec)\n",
    "        spec = data_transform(spec)    \n",
    "        \n",
    "    return spec\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Plot\n",
    "\"\"\"\n",
    "def plot_audio(path):\n",
    "    return ipd.Audio(path)\n",
    "\n",
    "\n",
    "def plot_wave(wav, title=\"wave\"):\n",
    "    waveshow(wav, x_axis='time')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_feature(feature, title=\"melspectrogram\"): ### ???\n",
    "    specshow(feature, x_axis='time', y_axis='hz')  ### ???\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Case study\n",
    "\"\"\"\n",
    "def audio_info(path, \n",
    "               sr=None, \n",
    "               features_dct={\"melspectrogram\": melspectrogram,\n",
    "                             \"mfcc\": mfcc}):\n",
    "\n",
    "    wav, sr = librosa.load(path, sr=sr)\n",
    "    plot_wave(wav)\n",
    "    for name, feature in features_dct.items():\n",
    "        f = get_feature(wav, sr=sr, feature=feature)\n",
    "        plot_feature(f, title=name)\n",
    "    return plot_audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = get_wave('../ESC-50-master/audio/1-100032-A-0.wav')\n",
    "spec = get_feature(wav, sr=sr, to_img=True, data_transform=transform_image(resize_shape=(32, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image.fromarray(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_float = get_feature(wav, sr=sr, to_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_float.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_feature(wav, sr=sr, to_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X, origin='lower')\n",
    "# plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_float, origin='lower')\n",
    "# plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = get_feature(wav, sr=sr, to_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X[:100, :150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "executionInfo": {
     "elapsed": 16293,
     "status": "ok",
     "timestamp": 1662379334606,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "Y1cHdML-cVRv",
    "outputId": "987b4930-acca-4ead-a29a-ac40baaca16d"
   },
   "outputs": [],
   "source": [
    "# audio_info('drive/MyDrive/DEEPSOUND/ESC-50-master/audio/1-100032-A-0.wav')\n",
    "audio_info('../ESC-50-master/audio/1-100032-A-0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3T5W-ghcVRx"
   },
   "source": [
    "###### Construct Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1662379338006,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "svBmVyEocVRx"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DF\n",
    "\"\"\"\n",
    "def _rename_targets(df):\n",
    "    map_dct = dict()\n",
    "    for i, target in enumerate(df.target.unique()):\n",
    "        map_dct[target] = i\n",
    "    df.target = df.target.map(map_dct)\n",
    "    return df\n",
    "        \n",
    "    \n",
    "def _get_df(path, only_esc10=True):\n",
    "    df = pd.read_csv(path)\n",
    "    if only_esc10:\n",
    "        print(f\"Use only 10 classes!\")\n",
    "        print()\n",
    "        df = df[df.esc10 == True]\n",
    "        df = _rename_targets(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _get_target_description(df):\n",
    "    return df[[\"target\", \"category\"]].groupby(\"target\").first()\n",
    "\n",
    "\n",
    "def _get_target_distribution(df, title=\"distribution_of_targets\", ax=None, show=False):    \n",
    "    ax = df.target.hist(bins=50, alpha=0.5, edgecolor=\"black\", ax=ax)\n",
    "    ax.set_xlabel(\"target\")\n",
    "    ax.set_ylabel(\"number_of_data_points\")\n",
    "    _min = df.target.min()\n",
    "    _max = df.target.max() + 1\n",
    "    plt.xticks(np.arange(_min, _max, 1))\n",
    "    if show:\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    else:\n",
    "        return ax\n",
    "    \n",
    "    \n",
    "def _get_folds(df):\n",
    "    fold_dct = dict()\n",
    "    for fold in df.fold.unique():\n",
    "        fold_dct[fold] = df[df.fold == fold]\n",
    "    return fold_dct\n",
    "\n",
    "\n",
    "def _get_folds_info(dct):\n",
    "    print(f\"Number_of_folds: {len(dct)}\")\n",
    "    print()\n",
    "    for i, fold in dct.items():\n",
    "        print(f\"fold: {i} | size: {fold.shape[0]}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "def _get_folds_distribution(dct):\n",
    "    print(\"Distribution of targets across folds:\")\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(dct), figsize=(20, 2), sharey=True)\n",
    "    for i, fold in dct.items():\n",
    "        _ax = axs[i - 1]\n",
    "        _get_target_distribution(fold, ax=_ax)\n",
    "        _ax.set_title(f\"fold_{i}\")\n",
    "    plt.show()         \n",
    "\n",
    "    \n",
    "def _get_number_of_classes(df):\n",
    "    return df.target.unique().shape[0]\n",
    "\n",
    "\n",
    "def _get_point_from_df(df, \n",
    "                       ind=0, \n",
    "                       base_dir='../ESC-50-master/audio', \n",
    "                       in_col='filename', \n",
    "                       out_col='target',\n",
    "                       feature=melspectrogram):\n",
    "    \n",
    "    row = df.iloc[ind]\n",
    "    file_name = row[in_col]\n",
    "    label = row[out_col]\n",
    "\n",
    "    file_path = os.path.join(base_dir, file_name)            \n",
    "    wav, sr = get_wave(file_path)\n",
    "    point_feature = get_feature(wav, sr=sr, feature=feature) ### to remake\n",
    "    return point_feature, label\n",
    "\n",
    "\n",
    "def _train_test_split(df, test_fold=1):\n",
    "    train_df = df[df.fold != test_fold]\n",
    "    test_df = df[df.fold == test_fold]\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Dataset\n",
    "\"\"\"   \n",
    "class ESC50Data(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 df,\n",
    "                 feature=melspectrogram,\n",
    "                 base_dir='../ESC-50-master/audio', \n",
    "                 in_col='filename', \n",
    "                 out_col='target'):\n",
    "        \n",
    "        self.df = df\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "                    \n",
    "        for ind in tqdm(range(len(df))):\n",
    "            point_feature, label = _get_point_from_df(df, \n",
    "                                                      ind=ind, \n",
    "                                                      base_dir=base_dir, \n",
    "                                                      in_col=in_col, \n",
    "                                                      out_col=out_col,\n",
    "                                                      feature=feature)\n",
    "                                        \n",
    "            self.data.append(point_feature[np.newaxis,...])            \n",
    "            self.labels.append(label)\n",
    "            \n",
    "                                        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "Loaders\n",
    "\"\"\"\n",
    "def get_loaders(df,\n",
    "                base_dir='../ESC-50-master/audio',\n",
    "                feature=melspectrogram,\n",
    "                test_fold=None, \n",
    "                batch_size=16):\n",
    "    \n",
    "    # 1. split\n",
    "    train_df = df\n",
    "    test_df = None\n",
    "    if test_fold is not None:\n",
    "        train_df, test_df = _train_test_split(df, test_fold=test_fold)\n",
    "\n",
    "    # 2. loaders\n",
    "    print(\"train_data:\")\n",
    "    train_data = ESC50Data(train_df, base_dir=base_dir, feature=feature)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_loader = None\n",
    "    if test_df is not None:\n",
    "        print(\"test_data:\")\n",
    "        test_data = ESC50Data(test_df, base_dir=base_dir, feature=feature)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True) ### !!!\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def get_cross_validation_loaders(df,\n",
    "                                 base_dir='../ESC-50-master/audio',\n",
    "                                 feature=melspectrogram, \n",
    "                                 batch_size=16):\n",
    "    \n",
    "    loaders = []\n",
    "    folds = df.fold.unique()\n",
    "    for fold in folds:\n",
    "        print(f\"--- FOLD: {fold} ---\")\n",
    "        train_loader, test_loader = get_loaders(df,\n",
    "                                                base_dir=base_dir,\n",
    "                                                feature=feature,\n",
    "                                                test_fold=fold, \n",
    "                                                batch_size=batch_size)\n",
    "        loaders.append((train_loader, test_loader))\n",
    "        \n",
    "    return loaders       \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Data Storage\n",
    "\"\"\"\n",
    "class DataStorage:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 base_dir=\"../ESC-50-master\",\n",
    "                 only_esc10=True,\n",
    "                 feature=melspectrogram,\n",
    "                 batch_size=16):\n",
    "        \n",
    "        csv_path = os.path.join(base_dir, \"meta\", \"esc50.csv\")\n",
    "        audio_dir_path = os.path.join(base_dir, \"audio\")\n",
    "        \n",
    "        assert os.path.isfile(csv_path)\n",
    "        assert os.path.isdir(audio_dir_path)\n",
    "        \n",
    "        self.csv_path = csv_path\n",
    "        self.audio_dir_path = audio_dir_path\n",
    "        self.feature = feature\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        df = _get_df(csv_path, only_esc10=only_esc10)\n",
    "        \n",
    "        self.df = df\n",
    "        self.folds = _get_folds(df)\n",
    "        self.target_description = _get_target_description(df)  \n",
    "        self.number_of_classes = _get_number_of_classes(df)\n",
    "        self.random_point_feature = self.get_ind_point_feature(ind=np.random.choice(df.shape[0]))\n",
    "        self.feature_shape = self.random_point_feature.shape\n",
    "        \n",
    "        print(f\"Number of points: {self.df.shape[0]}\")\n",
    "        print()\n",
    "        print(self.get_target_description())\n",
    "        print()\n",
    "        print(f\"Feature: {feature} | Shape: {self.feature_shape}\")\n",
    "        print()\n",
    "        self.get_cross_validation_loaders()\n",
    "        self.get_full_data_loader() ### ???\n",
    "        \n",
    "        \n",
    "    def get_ind_point_feature(self, ind=0):\n",
    "        point_feature, _ = _get_point_from_df(self.df, \n",
    "                                              ind=ind, \n",
    "                                              base_dir=self.audio_dir_path, \n",
    "                                              feature=self.feature)\n",
    "        return point_feature\n",
    "        \n",
    "        \n",
    "    def get_folds_description(self):\n",
    "        _get_folds_info(self.folds)\n",
    "        \n",
    "        \n",
    "    def get_folds_distribution(self):\n",
    "        _get_folds_distribution(self.folds)\n",
    "        \n",
    "        \n",
    "    def get_target_description(self):\n",
    "        return self.target_description\n",
    "    \n",
    "    \n",
    "    def get_target_distribution(self):\n",
    "        _get_target_distribution(self.df, show=True)\n",
    "        \n",
    "        \n",
    "    def get_cross_validation_loaders(self):\n",
    "        print(\"------ CONSTRUCT CROSS VALIDATION LOADERS------\")\n",
    "        print()\n",
    "        self.get_folds_description()\n",
    "        self.get_folds_distribution()\n",
    "        self.cross_validation_loaders = \\\n",
    "        get_cross_validation_loaders(self.df,\n",
    "                                     base_dir=self.audio_dir_path,\n",
    "                                     feature=self.feature, \n",
    "                                     batch_size=self.batch_size)\n",
    "    \n",
    "    \n",
    "    def get_full_data_loader(self):\n",
    "        print(\"------ CONSTRUCT FULL DATA LOADER------\")\n",
    "        print()\n",
    "        print(f\"Number of points: {self.df.shape[0]}\")\n",
    "        self.get_target_distribution()\n",
    "        self.full_data_loader, _ = \\\n",
    "        get_loaders(self.df,\n",
    "                    base_dir=self.audio_dir_path,\n",
    "                    feature=self.feature,\n",
    "                    test_fold=None, \n",
    "                    batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use only 10 classes!\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "img should be PIL Image. Got <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m DS \u001b[38;5;241m=\u001b[39m \u001b[43mDataStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mDataStorage.__init__\u001b[0;34m(self, base_dir, only_esc10, feature, batch_size)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_description \u001b[38;5;241m=\u001b[39m _get_target_description(df)  \n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_classes \u001b[38;5;241m=\u001b[39m _get_number_of_classes(df)\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_point_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ind_point_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_point_feature\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of points: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mDataStorage.get_ind_point_feature\u001b[0;34m(self, ind)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ind_point_feature\u001b[39m(\u001b[38;5;28mself\u001b[39m, ind\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 225\u001b[0m     point_feature, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_point_from_df\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_dir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m point_feature\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m_get_point_from_df\u001b[0;34m(df, ind, base_dir, in_col, out_col, feature)\u001b[0m\n\u001b[1;32m     80\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, file_name)            \n\u001b[1;32m     81\u001b[0m wav, sr \u001b[38;5;241m=\u001b[39m get_wave(file_path)\n\u001b[0;32m---> 82\u001b[0m point_feature \u001b[38;5;241m=\u001b[39m \u001b[43mget_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m### to remake\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m point_feature, label\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mget_feature\u001b[0;34m(wav, data_transform, power_to_db, to_img, feature, sr, n_fft, hop_length, n_mels, fmin, fmax, top_db)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_img:\n\u001b[1;32m     52\u001b[0m     spec \u001b[38;5;241m=\u001b[39m spec_to_image(spec)\n\u001b[0;32m---> 54\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[43mdata_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spec\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsound/lib/python3.9/site-packages/torchvision/transforms/transforms.py:60\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 60\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsound/lib/python3.9/site-packages/torchvision/transforms/transforms.py:195\u001b[0m, in \u001b[0;36mResize.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m        img (PIL Image): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m        PIL Image: Rescaled image.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepsound/lib/python3.9/site-packages/torchvision/transforms/functional.py:229\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Resize the input PIL Image to the given size.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    PIL Image: Resized image.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pil_image(img):\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg should be PIL Image. Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(img)))\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(size))\n",
      "\u001b[0;31mTypeError\u001b[0m: img should be PIL Image. Got <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "DS = DataStorage()\n",
    "\n",
    "# DS.get_cross_validation_loaders()\n",
    "# DS.get_full_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTjlUhiMcVR0"
   },
   "outputs": [],
   "source": [
    "DS.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_K2bFBflcVR1"
   },
   "outputs": [],
   "source": [
    "DS.random_point_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIJjKgO3cVR1"
   },
   "outputs": [],
   "source": [
    "DS.feature_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw1FsEiBcVR1"
   },
   "source": [
    "###### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1662380744266,
     "user": {
      "displayName": "Дмитрий Галимзянов",
      "userId": "11134509458244039564"
     },
     "user_tz": -180
    },
    "id": "1ZTmbmhPcVR2"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Model\n",
    "\"\"\"\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, in_dim=1*128*431, out_dim=50):\n",
    "#         super().__init__()\n",
    "#         self.network = nn.Sequential(\n",
    "#             nn.Linear(in_dim, out_dim))\n",
    "        \n",
    "#     def forward(self, xb):\n",
    "#         x = xb.flatten(start_dim=1)\n",
    "#         return self.network(x)\n",
    "\n",
    "    \n",
    "class Model(nn.Modele):\n",
    "    def __init__(self, in_dim=1*128*431, out_dim=50):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, out_dim))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)    \n",
    "    \n",
    "    \n",
    "def _init_model(in_dim=1*128*431, out_dim=50):\n",
    "    model = Model(in_dim=in_dim, out_dim=out_dim)\n",
    "#     model = resnet34(pretrained=True)\n",
    "#     model.fc = nn.Linear(512, 50)\n",
    "#     model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Train\n",
    "\"\"\"\n",
    "def train(model, \n",
    "          train_loader, \n",
    "          valid_loader,\n",
    "          epochs=50,\n",
    "          lr=2e-4,\n",
    "          gamma=0.96,\n",
    "          optim=Adam,\n",
    "          sheduler=ExponentialLR,\n",
    "          loss_fn=nn.CrossEntropyLoss()):\n",
    "      \n",
    "    \n",
    "    optimizer = optim(model.parameters(), lr=lr)\n",
    "    lr_scheduler = sheduler(optimizer=optimizer, gamma=gamma)\n",
    "        \n",
    "    train_losses = []\n",
    "    valid_losses = []    \n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        \n",
    "        # 1. train\n",
    "        model.train()        \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        batch_losses=[]\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            \n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            batch_losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = np.mean(batch_losses)    \n",
    "        train_losses.append(train_loss)\n",
    "        print(f'Epoch: {epoch} | Train_Loss : {train_loss}')\n",
    "        \n",
    "        \n",
    "        # 2. validate\n",
    "        if valid_loader is not None:\n",
    "            model.eval()\n",
    "            batch_losses=[]\n",
    "            trace_y = []\n",
    "            trace_y_hat = []\n",
    "\n",
    "            for i, data in enumerate(valid_loader):\n",
    "                x, y = data\n",
    "                x = x.to(device, dtype=torch.float32)\n",
    "                y = y.to(device, dtype=torch.long)\n",
    "\n",
    "                y_hat = model(x)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "                trace_y.append(y.cpu().detach().numpy())\n",
    "                trace_y_hat.append(y_hat.cpu().detach().numpy())      \n",
    "                batch_losses.append(loss.item())\n",
    "\n",
    "            valid_loss = np.mean(batch_losses[-1])    \n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "            trace_y = np.concatenate(trace_y)\n",
    "            trace_y_hat = np.concatenate(trace_y_hat)\n",
    "\n",
    "            accuracy = np.mean(trace_y_hat.argmax(axis=1) == trace_y) ## ???\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "            print(f\"Epoch: {epoch} | Valid_Loss : {valid_loss}\") \n",
    "            print(f\"Valid_Accuracy : {accuracy}\")\n",
    "    \n",
    "    return model, optimizer, train_losses, valid_losses\n",
    "\n",
    "    \n",
    "def plot_losses(train_losses, valid_losses):\n",
    "    epochs = len(train_losses)\n",
    "    x = np.linspace(1, epochs, epochs) \n",
    "    plt.plot(x, train_losses, label=\"train_loss\")\n",
    "    if len(valid_losses) > 0:\n",
    "        assert len(train_losses) == len(valid_losses)\n",
    "        plt.plot(x, valid_losses, label=\"validation_loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"Training process\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Main class\n",
    "\"\"\"\n",
    "class AudioClassifier:\n",
    "    \n",
    "    ### add lr plot\n",
    "    ### add std to mean score\n",
    "    \n",
    "    def __init__(self, data_storage):\n",
    "        self.data_storage = data_storage\n",
    "           \n",
    "            \n",
    "    def _fit(self, \n",
    "             train_loader, \n",
    "             test_loader,\n",
    "             plot_training=True):\n",
    "        \n",
    "        model = _init_model(in_dim=np.multiply(*self.data_storage.feature_shape),\n",
    "                            out_dim=self.data_storage.number_of_classes)\n",
    "        \n",
    "        model, optimizer, train_losses, test_losses = train(model,  \n",
    "                                                            train_loader, \n",
    "                                                            test_loader, \n",
    "                                                            epochs=self.epochs,\n",
    "                                                            lr=self.lr,\n",
    "                                                            gamma=self.gamma,\n",
    "                                                            optim=self.optim,\n",
    "                                                            sheduler=self.sheduler,\n",
    "                                                            loss_fn=self.loss_fn)\n",
    "        \n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = train_losses\n",
    "        self.test_losses = test_losses\n",
    "        if plot_training:\n",
    "            plot_losses(train_losses, test_losses)       \n",
    "    \n",
    "    \n",
    "    def fit(self, \n",
    "            epochs=50, \n",
    "            lr=2e-4,\n",
    "            gamma=0.96,\n",
    "            optim=Adam,\n",
    "            sheduler=ExponentialLR,\n",
    "            loss_fn=nn.CrossEntropyLoss(), \n",
    "            plot_training=True):\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.optim = optim\n",
    "        self.sheduler = sheduler\n",
    "        self.loss_fn = loss_fn\n",
    "         \n",
    "        self._fit(self.data_storage.full_data_loader, \n",
    "                  None,\n",
    "                  plot_training=plot_training)\n",
    "        \n",
    "        \n",
    "    def cross_validation(self, \n",
    "                         epochs=50, \n",
    "                            lr=2e-4,\n",
    "                            gamma=0.96,\n",
    "                            optim=Adam,\n",
    "                            sheduler=ExponentialLR,\n",
    "                            loss_fn=nn.CrossEntropyLoss(), \n",
    "                            plot_training=True):\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.optim = optim\n",
    "        self.sheduler = sheduler\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "        cross_val_score_s = []\n",
    "        for i, (train_loader, test_loader) in enumerate(self.data_storage.cross_validation_loaders):\n",
    "            print(f\"--- CROSS VALIDATION | FOLD: {i + 1} ---\")\n",
    "            self._fit(train_loader, \n",
    "                      test_loader, \n",
    "                      plot_training=plot_training)\n",
    "            \n",
    "            score = self.test_losses[-1]\n",
    "            cross_val_score_s.append(score)\n",
    "\n",
    "        self.cross_val_score_s = cross_val_score_s\n",
    "        self.cross_val_score = np.mean(cross_val_score_s)\n",
    "        print()\n",
    "        print(f\"--- CROSS VALIDATION SCORE: {self.cross_val_score} ---\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "    def predict(self, loader): \n",
    "        ### improve\n",
    "        trace_y_hat = []\n",
    "        self.model.eval()\n",
    "        for i, data in enumerate(loader):\n",
    "            x, y = data\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "\n",
    "            y_hat = self.model(x)\n",
    "            trace_y_hat.append(y_hat.cpu().detach().numpy())      \n",
    "\n",
    "        return trace_y_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sKqyaZqzOc0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "\n",
    "clf = AudioClassifier(DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.data_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.cross_validation(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIO0vLq1cVR3"
   },
   "outputs": [],
   "source": [
    "clf.mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTFl33nfcVR3"
   },
   "outputs": [],
   "source": [
    "clf.cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(full_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
